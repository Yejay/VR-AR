Wofür steht XR?,XR steht für Extended Reality.
Erklären Sie XR.,"XR (Extended Reality) ist der Sammelbegriff für alle immersiven Technologien. Es umfasst VR (Virtual Reality), AR (Augmented Reality) und MR (Mixed Reality). XR beschreibt das gesamte Spektrum zwischen realer und virtueller Umgebung."
"Nennen Sie die drei Technologien, die unter XR fallen, und beschreiben Sie jeweils in einem Satz, was sie bedeuten.","VR (Virtual Reality): Nutzer ist komplett in eine digital generierte Umgebung eingetaucht, die reale Welt wird vollständig ausgeblendet. AR (Augmented Reality): Die reale Welt wird durch digitale Elemente erweitert, wobei die Realität sichtbar bleibt. MR (Mixed Reality): Virtuelle und reale Objekte interagieren miteinander, z.B. reagiert ein virtuelles Objekt auf die Physik der realen Welt."
Nennen Sie drei Besonderheiten des VR-Renderings gegenüber herkömmlichem Rendering.,"Lens Distortion (und inverse Distortion), Chromatic Aberration, Stereoscopic Rendering."
"Erläutern Sie, was man unter Stereoscopic Rendering versteht.","Beim stereoskopischen Rendering werden zwei leicht versetzte Bilder gerendert – eines für jedes Auge. Der Versatz entspricht der Interpupillardistanz (IPD), also dem Abstand zwischen den Augen. Dadurch entsteht im Gehirn ein räumlicher 3D-Tiefeneffekt, wie wir ihn auch beim natürlichen Sehen haben. Nachteil ist die verdoppelte Render-Last."
Erklären Sie das Problem der Lens Distortion und wie es gelöst wird.,"VR-Linsen (meist Fresnel-Linsen) erzeugen eine Pincushion-Distortion (Kissenverzerrung), wodurch das Bild verzerrt wahrgenommen würde. Die Lösung: Die Software wendet beim Rendern eine Barrel-Distortion (Tonnenverzerrung) an. Da beide Verzerrungen entgegengesetzt sind, heben sie sich gegenseitig auf und das Bild erscheint korrekt."
Was ist Chromatic Aberration und wie wird sie korrigiert?,"Chromatic Aberration ist ein Farbfehler, bei dem Linsen verschiedene Lichtwellenlängen (Farben) unterschiedlich stark brechen. Dadurch entstehen Farbsäume an den Bildrändern. Die Korrektur erfolgt durch Verschiebung der einzelnen Farbkanäle (RGB) beim Rendern im Post-Processing."
Was ist Frustum Culling und worin unterscheidet sich VR Frustum Culling vom traditionellen?,"Frustum Culling ist eine Optimierungstechnik, bei der Objekte außerhalb des Sichtfelds (Frustum) nicht gerendert werden. Traditionell ist das Frustum pyramidenförmig, da Monitore rechteckig sind. Bei VR ist das Frustum kegelförmig, weil die Linsen rund sind."
Erläutern Sie das Prinzip von Foveated Rendering.,"Beim Foveated Rendering wird nur der Bereich scharf gerendert, den das Auge gerade fokussiert (Fovea). Der periphere Bereich wird mit geringerer Auflösung gerendert. Dies spart massiv Rechenleistung. Voraussetzung ist Eye-Tracking, um zu wissen, wohin der Nutzer schaut. Ohne Eye-Tracking gibt es ""Fixed Foveated Rendering"", bei dem nur die Bildmitte scharf gerendert wird."
Was ist Space Warp (ASW)?,"Space Warp (Asynchronous Space Warp) ist eine Technik, die künstliche Zwischenframes generiert, wenn die GPU die Ziel-Framerate (z.B. 90Hz) nicht halten kann. Dadurch wird die benötigte Rechenleistung um bis zu 70% reduziert und Motion Sickness durch niedrige Framerates wird verhindert."
Erklären Sie den Unterschied zwischen 3DoF und 6DoF.,"3DoF (3 Degrees of Freedom) erfasst nur die Rotation des Kopfes in drei Achsen: Yaw (links/rechts drehen), Pitch (oben/unten neigen) und Roll (zur Seite kippen). Die Position im Raum wird nicht erfasst. 6DoF (6 Degrees of Freedom) erfasst zusätzlich zur Rotation auch die Position im Raum (Bewegung in x, y, z). Beispiel: Google Cardboard hat 3DoF, Meta Quest 2 hat 6DoF."
Was ist eine IMU und aus welchen Komponenten besteht sie?,"IMU steht für Inertial Measurement Unit – ein Sensor zur Bewegungserkennung. Sie besteht aus drei Komponenten: Accelerometer (misst lineare Beschleunigung inkl. Schwerkraft), Gyroskop (misst Winkelgeschwindigkeit/Rotation), Magnetometer (misst Magnetfelder zur Drift-Korrektur und Nordausrichtung)."
Nennen Sie zwei Tracking-Arten und jeweils einen Vor- und Nachteil.,"Lighthouse (Outside-In): Stationäre Laser-Basisstationen im Raum. Vorteil: Sehr präzise. Nachteil: Aufwendiger Aufbau und Verdeckungsprobleme möglich. Inside-Out: Kameras am Headset scannen die Umgebung. Vorteil: Kein Aufbau nötig, theoretisch unbegrenzter Bewegungsraum. Nachteil: Rechenintensiv, Controller-Tracking hinter dem Rücken problematisch."
Nennen Sie die drei Rotationsachsen und beschreiben Sie die zugehörige Bewegung.,"Yaw (Gieren): Kopf nach links/rechts drehen. Pitch (Nicken): Kopf nach oben/unten neigen. Roll (Rollen): Kopf zur Seite kippen."
Was ist Immersion?,"Immersion ist eine objektive, technische Eigenschaft des VR-Systems. Sie beschreibt die Qualität der technischen Faktoren wie Field of View (FOV), Auflösung, Tracking-Qualität und Framerate. Die Technologie ermöglicht das ""Eintauchen"" in die virtuelle Welt. Auch andere Medien wie Bücher können Immersion erzeugen."
Was ist Presence?,"Presence ist das subjektive, psychologische Gefühl, wirklich ""dort"" zu sein (""Being there""). Es ist die persönliche Wahrnehmung, sich tatsächlich in der virtuellen Umgebung zu befinden, obwohl man weiß, dass man es nicht ist."
Erläutern Sie den Unterschied zwischen Immersion und Presence.,"Immersion ist objektiv und technisch – sie beschreibt die Eigenschaften des Systems (FOV, Auflösung, Tracking). Presence ist subjektiv und psychologisch – das Gefühl, wirklich ""dort"" zu sein. Wichtig: Ohne Immersion kann keine Presence entstehen. Die Technologie (Immersion) schafft erst die Voraussetzung für das Gefühl (Presence)."
Was ist Self-Embodiment?,"Self-Embodiment ist das Gefühl, dass der virtuelle Körper (Avatar) der eigene Körper ist. Der Nutzer nimmt den virtuellen Körper als Teil von sich selbst wahr und identifiziert sich mit ihm."
Nennen Sie drei Gründe für ungewollte Unterbrechungen der Presence (Break-in-Presence).,"Tracking-Verlust, Lags/hohe Latenz, Kabelberührung, reale Geräusche von außen, niedrige Framerate."
Wann will man die Presence absichtlich unterbrechen?,"Aus Sicherheitsgründen, z.B. durch das Chaperone/Guardian-System. Dieses zeigt Gitterlinien an, wenn sich der Nutzer einer realen Wand oder einem Hindernis nähert, um Kollisionen zu verhindern."
Was versteht man unter Comfort Zone in VR und warum ist sie wichtig?,"Die Comfort Zone ist der persönliche Abstand, den Menschen auch in VR benötigen. Wenn virtuelle NPCs, Charaktere oder Objekte zu nah kommen (z.B. ""ins Gesicht fliegen"" oder ""Nacken atmen""), erzeugt das Stress und Unbehagen beim Nutzer. VR-Designer müssen diese Zone respektieren, um eine angenehme Erfahrung zu schaffen."
Erklären Sie das Konzept des Uncanny Valley.,"Das Uncanny Valley beschreibt eine Akzeptanzlücke bei fast menschenähnlichen Figuren. Wenn virtuelle Charaktere sehr menschlich aussehen, aber nicht perfekt sind, wirken sie gruselig, unheimlich oder zombiehaft. Die Akzeptanz sinkt stark ab. Wird die Darstellung noch realistischer und perfekter, steigt die Akzeptanz wieder an."
"Erklären Sie, wie Motion Sickness in VR entsteht.","Motion Sickness entsteht durch einen sensorischen Konflikt (Sensory Conflict Theory): Das Auge sieht Bewegung in der virtuellen Welt, aber das Vestibularorgan (Innenohr) spürt Stillstand, da der Körper sich real nicht bewegt. Der Körper interpretiert diese Diskrepanz als Vergiftungssymptom und reagiert mit Übelkeit."
Nennen Sie fünf Risikofaktoren für Motion Sickness.,"1. Frauen sind statistisch anfälliger. 2. Kinder sind anfälliger. 3. Niedrige Framerate (unter 90 FPS). 4. Hohe Latenz. 5. Künstliche Rotation oder Bewegung (Smooth Locomotion)."
Nennen Sie Symptome von Motion Sickness.,"Übelkeit, Schwindel, Schweißausbrüche, Kopfschmerzen, Desorientierung, allgemeines Unwohlsein."
Nennen Sie vier Maßnahmen zur Reduzierung von Motion Sickness.,"1. Hohe Framerate (90+ FPS). 2. Teleportation statt künstlicher Smooth-Bewegung. 3. Statische Referenzpunkte (künstlicher Horizont, Cockpit, Nasenmodell). 4. Natürliche 1-zu-1 Bewegung ermöglichen."
Was muss man beim Design von VR User Interfaces im Vergleich zu klassischen UIs beachten?,"Klassische 2D-Overlays (Screen Space UI) funktionieren in VR schlecht, da sie Fokus-Probleme und Verdeckungen verursachen. VR UIs müssen im 3D-Raum positioniert sein (World Space / Floating Interface). Sie sollten im angenehmen Sichtbereich (Comfortable Viewing) platziert werden, um Nackenschmerzen durch ständiges Kopfdrehen zu vermeiden."
Was sind Interface Objects (diegetische Interfaces) in VR?,"Interface Objects sind UI-Elemente, die als Teil der Spielwelt integriert sind. Beispiele: Eine Lebensanzeige auf einer Armbanduhr des Charakters oder eine Munitionsanzeige direkt auf der Waffe. Der Vorteil ist eine erhöhte Immersion, da die Informationen nicht als externe UI-Elemente wahrgenommen werden."
Was bedeutet Affordance im Kontext von VR?,"Affordance bedeutet, dass das Design eines Objekts seine Funktion kommuniziert. Ein Griff sieht greifbar aus, ein Knopf sieht drückbar aus, ein Hebel sieht ziehbar aus. In VR ist dies besonders wichtig, da Nutzer ohne Anleitung intuitiv verstehen müssen, wie sie mit Objekten interagieren können."
Nennen Sie die vier Viewing Zones bei VR Interfaces.,"1. Comfortable Viewing: Angenehmer Sichtbereich ohne Kopfbewegung. 2. Peripheral Viewing: Peripheres Sichtfeld (Augenwinkel). 3. Rotational Viewing: Erfordert Kopfdrehung. 4. Curiosity Zone: Erfordert Körperdrehung."
Definieren Sie VR Interaction.,"VR Interaction besteht aus zwei Komponenten: einer Aktion des Nutzers und der entsprechenden Reaktion der VR-Anwendung auf diese Aktion."
Was besagt das Universal Simulation Principle nach Lavalle?,"Das Universal Simulation Principle besagt, dass jede Interaktion der realen Welt in VR simuliert werden kann. Dazu gehören natürliche Aktionen wie Greifen, Werfen, Schieben, Drücken, Ziehen und alle anderen physischen Interaktionen."
Nennen Sie drei Feedback-Arten bei VR Interactions und geben Sie jeweils ein Beispiel.,"Visuell: Objekt leuchtet auf oder ändert die Farbe bei Berührung (Highlight). Auditiv: Sound beim Berühren, Aufheben oder Einrasten eines Objekts. Haptisch: Vibration des Controllers (Rumble) bei Kollision oder Interaktion."
Was ist das Kernproblem bei VR Locomotion?,"Die virtuelle Welt ist theoretisch unbegrenzt groß, während der physische Raum des Nutzers stark begrenzt ist (z.B. ein Wohnzimmer). Es muss eine Lösung gefunden werden, wie man sich in einer unendlichen virtuellen Welt frei bewegen kann, ohne dabei Motion Sickness zu erzeugen."
Erklären Sie den Unterschied zwischen Blink- und Shift/Dash-Teleportation.,"Blink: Der Bildschirm wird kurz schwarz und der Nutzer erscheint am neuen Ort. Sehr komfortabel und Motion-Sickness-frei, aber man verliert kurz die räumliche Orientierung. Shift/Dash: Der Nutzer gleitet schnell zum Zielort, die Bewegung ist sichtbar. Bessere räumliche Orientierung, aber höheres Motion-Sickness-Risiko."
Was sind Impossible Spaces?,"Impossible Spaces sind virtuelle Räume, die sich überlappen, was in der realen Welt nicht möglich wäre. Sie ignorieren die euklidische Geometrie, um den begrenzten physischen Raum besser zu nutzen. Der Nutzer bemerkt nicht, dass er denselben realen Raum mehrfach durchquert, während er verschiedene virtuelle Räume erkundet."
Erläutern Sie das Prinzip von Redirected Walking.,"Bei Redirected Walking wird der Nutzer unmerklich manipuliert. Er läuft beispielsweise in der Realität im Kreis, glaubt aber virtuell geradeaus zu gehen. Dies basiert auf der Beobachtung, dass Menschen kleine Abweichungen zwischen visueller und physischer Bewegung nicht bemerken."
Nennen und erklären Sie drei Gain-Typen bei Redirected Walking.,"Rotation Gain: Virtuelle Rotation weicht von realer ab. Beispiel: Nutzer dreht sich real 90°, virtuell werden 100° angezeigt. Translation Gain: Virtuelle Strecke weicht von realer ab. Beispiel: Nutzer läuft real 1m, virtuell werden 1.2m zurückgelegt. Curvature Gain: Eine Kurve fühlt sich wie eine Gerade an. Nutzer läuft real eine Kurve, sieht virtuell aber einen geraden Weg."
Nennen Sie die drei definierenden Eigenschaften von AR nach Azuma.,"1. Kombiniert Realität und Virtualität. 2. Interaktiv in Echtzeit. 3. Registriert im 3D-Raum (räumlich verankert)."
Was ist kein AR?,"Einfache 2D-Overlays ohne räumliche Verankerung sind kein AR. Beispiel: Ein Navigationspfeil, der fest auf dem Bildschirm liegt und nicht im 3D-Raum registriert ist. AR erfordert, dass digitale Objekte räumlich in der realen Welt verankert sind."
Erklären Sie den Unterschied zwischen Optical See-Through und Video See-Through.,"Optical See-Through (z.B. HoloLens): Der Nutzer sieht die reale Welt direkt durch transparente Gläser, virtuelle Objekte werden auf diese eingeblendet. Vorteile: Keine Latenz, native Auflösung der Realität, sicher bei Stromausfall. Nachteile: Kleines FOV für virtuelle Objekte, Schwarz nicht darstellbar, schwierige Okklusion. Video See-Through (z.B. Quest 3): Kameras filmen die Realität, die dann zusammen mit virtuellen Objekten auf dem Display angezeigt wird. Vorteile: Großes FOV, Okklusion einfach umsetzbar, Schwarz darstellbar. Nachteile: Latenz bei der Realitätsdarstellung, Auflösung durch Kamera begrenzt."
Was ist Spatial AR?,"Bei Spatial AR projizieren Beamer direkt auf echte Objekte oder Oberflächen (Projection Mapping). Der große Vorteil ist, dass keine Brille oder kein Headset benötigt wird."
Was ist der Unterschied zwischen Feature Detection und Feature Matching?,"Feature Detection: Findet markante Punkte im Bild wie Ecken und Kanten. Algorithmen: Harris Corner Detection, FAST. Feature Matching: Erkennt die gefundenen Punkte in neuen Bildern wieder, um Tracking zu ermöglichen. Algorithmen: SIFT (skaleninvariant), FLANN."
Was sind Fiducial Marker und welche Eigenschaften haben sie?,"Fiducial Marker sind schwarz-weiße Muster, ähnlich wie QR-Codes, die speziell für AR-Tracking entwickelt wurden. Beispiele sind ARToolKit, ARTag, AprilTag und ArUco. Eigenschaften: Sie sind extrem schnell, robust und präzise erkennbar, da ihre Größe und Form dem System bekannt sind."
Wie funktioniert Plane Detection?,"Bei der Plane Detection werden aus einer Punktwolke (Point Cloud) Gruppen von Punkten erkannt, die in einer Ebene liegen. Durch Feature Movement Tracking kann zwischen horizontalen Flächen (Boden, Tisch) und vertikalen Flächen (Wände) unterschieden werden. Dies ermöglicht das Platzieren virtueller Objekte auf realen Oberflächen."
Nennen Sie zwei Render-Challenges bei AR und erklären Sie die Lösungen.,"Occlusion (Verdeckung): Problem: Virtuelle Objekte müssen hinter realen Objekten verschwinden können. Lösung: Phantom Shader / Phantom Objects – unsichtbare 3D-Hüllen der realen Objekte, die nur in den Tiefenpuffer schreiben und so virtuelle Objekte verdecken. Lighting: Problem: Virtuelle Objekte brauchen passende Schatten und Beleuchtung. Lösung: Light Estimation – die reale Lichtquelle wird erkannt und für die Schattenberechnung der virtuellen Objekte verwendet."
Nennen Sie drei Input-Typen für AR auf HMDs.,"Hand Tracking, Eye Tracking, Gesten, Controller, Device Movement (als virtuelle Kamera)."
Nennen Sie Input-Typen für mobile AR.,"Touch Input (Single-Touch und Multi-Touch), Device Movement (Smartphone als virtuelle Kamera)."
Nennen Sie Output-Typen für mobile AR und HMD-basierte AR.,"Mobile: Visual (Bildschirm), Audio (Lautsprecher), Haptics (Vibration im Gerät). HMD: Stereoscopic Visual, Stereo Audio, Haptics (Vibration in Controllern und HMD)."
